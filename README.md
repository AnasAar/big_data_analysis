# big_data_analysis
In this project, we implemented a Big Data architecture in the form of a data warehouse lake using a selection of technologies, including Hadoop, Hbase, Spark, web scraping, and AI models. The goal of this project was to consolidate and analyze public data from the website "marchespublics.gov.ma". To achieve this, we used web scraping techniques to extract various document formats, including .pdf, .png, .jpg, .jpeg, .doc, .docx, .ppt, and .zip files. We then applied data cleansing and transformation techniques to convert these documents into .txt files and used AI models and natural language processing tools to extract relevant data. The resulting data was stored in .csv files and loaded into the Hadoop ecosystem using HDFS commands. We also configured Anaconda and a virtual environment to run a Jupyter
notebook, and used PySpark to conduct further analysis. This project demonstrates the effectiveness of using a diverse set of tools and techniques to build a robust Big Data architecture for the consolidation and analysis of public data.
